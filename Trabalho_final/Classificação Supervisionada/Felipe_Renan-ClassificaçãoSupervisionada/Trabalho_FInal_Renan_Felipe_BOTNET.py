# -*- coding: utf-8 -*-
"""Trabaio IA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15ZFIbkexvIFBYZYdkzhUbCFphN-3VDkn
"""




#COLOCAR ARQUIVOS CSV NO MESMO DIRETORIO (FOLDER) do VSCODE QUE ESSE .py 
import pandas as pd


def merge_files(attack_csv, normal_csv, output_csv):

    #Carrega os dois arquivos csv separando tráfego em ataque e normal
    df_attack = pd.read_csv(attack_csv)
    df_normal = pd.read_csv(normal_csv)

    #Cria coluna de label com attack e normal
    df_attack["label"] = "attack"
    df_normal["label"] = "normal"

    #Concatena os dois dataframes
    df_full = pd.concat([df_attack, df_normal], ignore_index=True)

    #salva arquivo final
    df_full.to_csv(output_csv, index=False)
    #fim


if __name__ == "__main__":
  merge_files("attack.csv", "normal.csv", "data_merge.csv")

from sklearn.utils import resample



def balance_dataset(input_csv, output_csv, class_column):

    #Carrega arquivo de merge
    df = pd.read_csv(input_csv)

    # Conta numero de classes
    class_counts = df[class_column].value_counts()

    # Identifica classe minoritária
    min_count = class_counts.min()


    # Fazer undersampling para cada classe
    balanced_frames = []

    for c in class_counts.index:
        df_class = df[df[class_column] == c]
        df_down = resample(df_class,
                           replace=False,     # sem replicação
                           n_samples=min_count,
                           random_state=42)
        balanced_frames.append(df_down)

    # Concatena ressamples
    df_balanced = pd.concat(balanced_frames).sample(frac=1, random_state=42)

    # Salva csv balanceado
    df_balanced.to_csv(output_csv, index=False)

    #Fim


if __name__ == "__main__":
    balance_dataset("data_merge.csv", "data_balanced.csv", "label")

def clean(input_csv, output_csv, label_column):

    #Carrega csv balanceado
    df = pd.read_csv(input_csv)

    # Remove colunas desnecessárias
    drop_cols = [c for c in df.columns if "Unnamed" in c or c.lower() == "label"]
    drop_cols = [c for c in drop_cols if c != label_column]
    df = df.drop(columns=drop_cols)

    #Remove coluna label presente no dataset original
    if "Label" in df.columns and label_column != "Label":
        df = df.drop(columns=["Label"])

    #Salva csv clean
    df.to_csv(output_csv, index=False)
    #fin...

if __name__ == "__main__":
    clean("data_balanced.csv", "data_clean.csv", "label")

from sklearn.preprocessing import MinMaxScaler


def normalize(input_csv, output_csv, label_column):

    #Carrega csv clean
    df = pd.read_csv(input_csv)

    #separa label das features
    labels = df[label_column]
    features = df.drop(columns=[label_column])

    #Inicializa scaler e aplica fit transform
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(features)

    #Atualiza dataframe normalizado
    df_scaled = pd.DataFrame(scaled, columns=features.columns)
    df_scaled[label_column] = labels

    #Salva csv normalizado
    df_scaled.to_csv(output_csv, index=False)

    #fim..?

if __name__ == "__main__":
    normalize("data_clean.csv", "data_normalized.csv", "label")

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score, confusion_matrix
)
import matplotlib.pyplot as plt
import numpy as np


#função para treinar arvore aleatória --- Entradas :( csv normalizado , coluna de classificação )
def train_rf(input_csv, label_column):

    #Leitura de dataset
    df = pd.read_csv(input_csv)

    #Separação de features e labels
    y = df[label_column]
    X = df.drop(columns=[label_column])

    #Divisão entre treino e teste (20/80 %)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    #Treino de RF
    model = RandomForestClassifier(
        n_estimators=200,
        random_state=42,
        #N_jobs define a quantidade de cores da CPU que podem ser utilizados
        #No caso , n_job = -1 significa usar todos os disponíveis.
        n_jobs=-1
    )

    model.fit(X_train, y_train)

    #Avaliação de modelo de RF
    y_pred = model.predict(X_test)
    attack_index = list(model.classes_).index("attack")
    y_proba = model.predict_proba(X_test)[:, attack_index]

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, pos_label="attack")
    rec = recall_score(y_test, y_pred, pos_label="attack")
    f1 = f1_score(y_test, y_pred, pos_label="attack")

    # para AUC, precisamos converter labels "normal"/"attack" para 0/1
    y_test_bin = y_test.map({"normal": 0, "attack": 1})
    auc = roc_auc_score(y_test_bin, y_proba)

    #Calculo de matriz de Confusão
    cm = confusion_matrix(y_test, y_pred)

    print("\n=== RESULTADOS DO RANDOM FOREST ===")
    print(f"Accurácia:  {acc:.4f}")
    print(f"Precisão:   {prec:.4f}")
    print(f"Recall:     {rec:.4f}")
    print(f"F1:         {f1:.4f}")
    print(f"AUC:        {auc:.4f}")

    # Geração de arquivo csv que armazena grau de importância das features
    importances = pd.DataFrame({
        "feature": X.columns,
        "importance": model.feature_importances_
    }).sort_values("importance", ascending=False)

    importances.to_csv("feature_importance_rf.csv", index=False)


    # Geração de gráfico de Matriz de confusão por matplotlib
    classes = ["normal", "attack"]

    plt.figure(figsize=(6,5))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title("Matriz de Confusão")
    plt.colorbar()

    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes)
    plt.yticks(tick_marks, classes)


    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], "d"),
                    horizontalalignment="center",
                    color="white" if cm[i, j] > thresh else "black")

    plt.ylabel("Classe Verdadeira")
    plt.xlabel("Classe Prevista")
    plt.tight_layout()
    plt.show()


#fim!
if __name__ == "__main__":

    train_rf("data_normalized.csv", "label")